{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlplab/anaconda3/envs/development/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 1376\n",
      "[nltk_data] Downloading package punkt to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Global seed set to 1376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1376"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://github.com/amazon-science/efficient-longdoc-classification\n",
    "from functools import partial\n",
    "import nltk\n",
    "import pickle as pk\n",
    "import torch\n",
    "from context_enforcement.models.context_enforcer import compute_context_boundary\n",
    "from context_enforcement.trainers.train_bart import model_init\n",
    "from context_enforcement.data.common import create_text_tokenizer, SmartCollator\n",
    "from context_enforcement.trainers.common import get_dataset_specified_tasks\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "seed_everything(1376)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=torch.ones((1,2),dtype=torch.long,device='cuda')\n",
    "z.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(is_baseline=False, model_base='facebook/bart-base', output_dir='trained_models_sum_boundary/', task_type='xsum', run_id='bart_base_model_context_enforcer_250', eval_steps=1000, learning_rate=5e-05, max_seq_len=800, evaluation_strategy='epoch', save_strategy='epoch', seed=10, lr_scheduler_type='linear', weight_decay=0.0, warmup_ratio=0.25, num_train_epochs=10, save_total_limit=1, per_device_train_batch_size=12, per_device_eval_batch_size=12, gradient_accumulation_steps=4, fp16=True, verbose=False, context_max_len=250)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs= pk.load(open(\"trained_models_sum_boundary/train_args.ap\",'rb'))\n",
    "context_max_len=configs.context_max_len\n",
    "context_max_len_list = [context_max_len]#,300,450]\n",
    "context_sampling_bounds=(0.1, 0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'facebook/bart-base'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.model_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xsum (/home/nlplab/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)\n",
      "100%|██████████| 3/3 [00:00<00:00, 472.72it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_text_tokenizer(configs.model_base)\n",
    "\n",
    "task_dataset_gen = get_dataset_specified_tasks(configs.task_type)\n",
    "\n",
    "train_dataset = None\n",
    "eval_dataset = None\n",
    "test_dataset = None\n",
    "if task_dataset_gen is not None:\n",
    "    raw_dataset = task_dataset_gen(tokenizer=tokenizer, )\n",
    "    train_dataset = raw_dataset['train']\n",
    "    eval_dataset = raw_dataset['validation']\n",
    "    test_dataset = raw_dataset['test']\n",
    "\n",
    "model_builder = model_init(\n",
    "        vocab_size=len(train_dataset.tokenizer),\n",
    "        model_base=configs.model_base,\n",
    "        context_max_len = context_max_len,\n",
    "        context_sampling_bounds = context_sampling_bounds,\n",
    "        context_max_len_list= context_max_len_list,#is_baseline=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForContextualRecovery were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['encoder.layers.4.context_enforcer_layer_norm.bias', 'encoder.layers.3.context_enforcer._wrc.weight', 'encoder.layers.5.context_enforcer._wrc.bias', 'encoder.layers.2.context_enforcer._left_mha.out_proj.bias', 'encoder.layers.5.context_enforcer._wlc.bias', 'encoder.layers.2.context_enforcer._left_mha.in_proj_bias', 'encoder.layers.2.context_enforcer._wlc.bias', 'encoder.layers.2.context_enforcer._wlc.weight', 'encoder.layers.3.context_enforcer._right_mha.out_proj.weight', 'encoder.layers.5.context_enforcer._right_mha.in_proj_bias', 'encoder.layers.3.context_enforcer_layer_norm.bias', 'encoder.layers.5.context_enforcer._right_mha.out_proj.weight', 'encoder.layers.5.context_enforcer._left_mha.in_proj_weight', 'encoder.layers.4.context_enforcer._right_mha.in_proj_bias', 'encoder.layers.4.context_enforcer._left_mha.in_proj_bias', 'encoder.layers.4.context_enforcer._wrc.bias', 'encoder.layers.3.context_enforcer_layer_norm.weight', 'encoder.layers.5.context_enforcer_layer_norm.weight', 'encoder.layers.2.context_enforcer._left_mha.in_proj_weight', 'encoder.layers.2.context_enforcer_layer_norm.bias', 'encoder.layers.5.context_enforcer._left_mha.out_proj.bias', 'encoder.layers.3.context_enforcer._wlc.weight', 'encoder.layers.3.context_enforcer._left_mha.out_proj.weight', 'encoder.layers.2.context_enforcer._right_mha.out_proj.bias', 'encoder.layers.4.context_enforcer._right_mha.out_proj.bias', 'encoder.layers.5.context_enforcer._right_mha.out_proj.bias', 'encoder.layers.5.context_enforcer._right_mha.in_proj_weight', 'encoder.layers.3.context_enforcer._wlc.bias', 'encoder.layers.3.context_enforcer._right_mha.in_proj_weight', 'encoder.layers.4.context_enforcer_layer_norm.weight', 'encoder.layers.2.context_enforcer._right_mha.in_proj_bias', 'encoder.layers.2.context_enforcer._wrc.bias', 'encoder.layers.3.context_enforcer._left_mha.out_proj.bias', 'encoder.layers.5.context_enforcer_layer_norm.bias', 'encoder.layers.4.context_enforcer._wrc.weight', 'encoder.layers.3.context_enforcer._right_mha.out_proj.bias', 'encoder.layers.5.context_enforcer._wlc.weight', 'encoder.layers.4.context_enforcer._wlc.bias', 'encoder.layers.2.context_enforcer._right_mha.out_proj.weight', 'encoder.layers.2.context_enforcer._wrc.weight', 'encoder.layers.5.context_enforcer._left_mha.out_proj.weight', 'encoder.layers.2.context_enforcer._right_mha.in_proj_weight', 'encoder.layers.4.context_enforcer._left_mha.in_proj_weight', 'encoder.layers.3.context_enforcer._wrc.bias', 'encoder.layers.4.context_enforcer._left_mha.out_proj.bias', 'encoder.layers.4.context_enforcer._wlc.weight', 'encoder.layers.4.context_enforcer._right_mha.out_proj.weight', 'encoder.layers.2.context_enforcer._left_mha.out_proj.weight', 'encoder.layers.4.context_enforcer._left_mha.out_proj.weight', 'encoder.layers.4.context_enforcer._right_mha.in_proj_weight', 'encoder.layers.3.context_enforcer._right_mha.in_proj_bias', 'encoder.layers.3.context_enforcer._left_mha.in_proj_bias', 'encoder.layers.3.context_enforcer._left_mha.in_proj_weight', 'encoder.layers.5.context_enforcer._wrc.weight', 'encoder.layers.5.context_enforcer._left_mha.in_proj_bias', 'encoder.layers.2.context_enforcer_layer_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "generator = model_builder()\n",
    "train_model_path = \"trained_models_sum_boundary/bart_base_model_context_enforcer/checkpoint-25506/pytorch_model.bin\"\n",
    "state_dict = torch.load(train_model_path)\n",
    "generator.load_state_dict(state_dict)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "te1= test_dataset[16]\n",
    "b_input_ids = te1.input_ids.view(1, -1).to(device)\n",
    "b_input_mask = te1.attention_mask.view(1, -1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "example= {'document':\"\"\"\n",
    "           The character Buzz Watson first appeared in the second episode of the first season, \"About Face\". \n",
    "           Originally a recurring role, as the series progressed the character's visibility increased until Buzz became one of the central characters. \n",
    "           In the season 1 episode \"Standards and Practices\", it was revealed that he speaks fluent Spanish, which he learned from his Mexican stepfather.\n",
    "           In the season 7 episode \"You Have the Right to Remain Jolly\", it was revealed he had a sister named Casey, who was played by Christine Woods.\n",
    "           \"\"\"}\n",
    "te1=test_dataset._process_data(example)\n",
    "b_input_ids = te1.input_ids.view(1, -1).to(device)\n",
    "b_input_mask = te1.attention_mask.view(1, -1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24, 137)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(1376)\n",
    "boundary_sample =  (0.15, 0.5)\n",
    "seq_len = te1.input_ids[:1024].shape[0]\n",
    "\n",
    "boundary_start = int(0.45*seq_len) \n",
    "context_boundary = compute_context_boundary(seq_len,context_max_len=context_max_len)\n",
    "context_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generator\u001b[39m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      3\u001b[0m     bb\u001b[39m=\u001b[39mgenerator\u001b[39m.\u001b[39mgenerate(input_ids\u001b[39m=\u001b[39mb_input_ids[:,:\u001b[39m1024\u001b[39m],\n\u001b[1;32m      4\u001b[0m                 attention_mask\u001b[39m=\u001b[39mb_input_mask[:,:\u001b[39m1024\u001b[39m],\n\u001b[1;32m      5\u001b[0m                 context_boundary\u001b[39m=\u001b[39mcontext_boundary,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         num_beams\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,\n\u001b[1;32m     11\u001b[0m         )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    bb=generator.generate(input_ids=b_input_ids[:,:1024],\n",
    "                attention_mask=b_input_mask[:,:1024],\n",
    "                context_boundary=context_boundary,\n",
    "                eos_token_id=test_dataset.tokenizer.eos_token_id,\n",
    "        max_length=169,\n",
    "        early_stopping=True,\n",
    "        use_cache=True,\n",
    "        num_beams=8,\n",
    "        )\n",
    "test_dataset.tokenizer.batch_decode(bb,clean_up_tokenization_spaces=True,skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Limiting access to federal research would do an \"enormous disservice\" to the US and the world according to former Nasa chief scientist.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.tokenizer.decode(te1.labels,clean_up_tokenization_spaces=True,skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1187])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te1.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr Waleed Abdalati told the BBC the that continued access to data is in \"everyone's best interest\".\n",
      "Many US scientists are rushing to copy information onto servers outside the control of the federal government.\n",
      "They are afraid the Trump administration will curb access to climate and other research.\n",
      "The President-elect has blown hot and cold on the issue of climate change, having previously tweeted about global warming being a hoax.\n",
      "On Wednesday, one of his advisers compared scientists who support the mainstream view on global warming to flat-Earthers.\n",
      "\"There was an overwhelming science that the Earth was flat and there was an overwhelming science that we were the centre of the world,\" said Anthony Scaramucci, a member of the Trump transition committee, on CNN.\n",
      "\"We get a lot of things wrong in the scientific community.\"\n",
      "Now at the Co-operative Institute for Research in Environmental Sciences, Dr Abdalati served as Nasa's chief scientist in 2011, for two years.\n",
      "He says it is too early to tell if this type of rhetoric from the Trump team will be backed up by action against scientists working on climate issues.\n",
      "\"I do think that when it comes to access to federal databases, and information that the taxpayers have paid for, there would have to be a tremendous paradigm shift to actively take steps to make those data unavailable, and I think doing so would be an enormous disservice to the citizens of this country and to the world in general,\" he said via email.\n",
      "\"I do think that the scientific community, educators, members of the private sector who rely on these data in their businesses, and others will need to make clear that continued access to these data, which have been paid for by the taxpayers, allows their full value to be realized and is in everyone's best interest.\"\n",
      "Other researchers are taking a more pessimistic view on the question of data access and are encouraging colleagues and students to make copies. Prof Robert Paterson, from the University of Texas, Austin, says that he learned this the hard way under the administration of George W Bush, another president cool on climate.\n",
      "\"Within a month of coming into office the EPA website went down for three weeks and when it went back up stuff wasn't available anymore,\" Prof Paterson told BBC News.\n",
      "\"If history repeats itself with another administration that is basically a naysayer to climate change science, I would say it would be prudent for folks to do what they can to keep as much as they can on mirror sites.\"\n",
      "Other scientists are concerned about nominations to key government areas such as former Texas governor Rick Perry at Department of Energy (DoE) and Oklahoma attorney general Scott Pruitt at the EPA. Both have heavily criticised the agencies they now lead.\n",
      "Attempts by the Trump transition team at the DoE to obtain a list of all those employees who had worked on climate change have provoked anger as well as fear.\n",
      "\"I was horrified by the report with regard to Department of Energy scientists being named.  We must stand up to that and I have said so. We are all DoE scientists in that regard,\" said Dr Kevin Trenberth who has been a lead author for the Intergovernmental Panel on Climate Change (IPCC) is a senior scientist at the US National Center for Atmospheric Research (NCAR).\n",
      "\"That is a pretty chilling action by an incoming administration - the rhetoric suggests that revenge is a valid response to people who disagree with you,\" said Prof Robert Paterson,\n",
      "The Energy department has refused to comply with the request and the Trump team has now said the questionnaire was \"not authorised\".\n",
      "Many researchers are worried that the anti-climate tone being struck by the incoming administration will have many serious consequences for scientists trying to do their jobs in real world situations.\n",
      "\"Flooding is a fact of life in Texas and the frequency with which we're seeing it is noticeably increasing,\" said Dr Shannon Van Zandt, at Texas A&M University.\n",
      "\"A lot of the tools that have been developed by Federal agencies have been designed to help communities predict the changes that they're going to see and if that is restricted we would lose the ability to help people understand and incorporate it into the decisions that they're making both at the local level and at the state policy level.\"\n",
      "But some in this field believe that the change of administration is a good moment to review the type of scientific questions that US researchers are asking.\n",
      "Marcel Crok is a Dutch science writer who doesn't support the scientific consensus on climate change. He says that much of the research in the field takes place in an echo chamber and he welcomes the fact that the Trump administration will challenge this.\n",
      "Mr Crok accepts that human emissions of carbon dioxide are warming the planet, but he questions the accepted view on how far and how rapidly temperatures will rise. Mainstream scientists, he says, rely on models that are over sensitive to carbon. He expects this to change under Trump.\n",
      "He said: \"What the field is trying to do is prove that the observational estimates are wrong and that the models are still right, and in my opinion this is exactly the problem. They should be more open minded, they should be open to the idea that the models are wrong!\"\n",
      "\"I hope that under a Trump regime at least there would be more funding, because if the funding agencies ask these kind of questions they can stimulate research in other directions than proving that the models are right all the time.\"\n",
      "The idea that aspects of climate research, supported by a minority, should now gain funding at the expense of the majority view, is dismissed by those in the field.\n",
      "\"It is not all spun, it is not all one side or the other,\" said Prof James White from the Institute of Arctic and Alpine Research at the University of Colorado.\n",
      "\"This is good unbiased information, it would be a real shame if that data is turned off.\"\n",
      "Follow Matt on Twitter and on Facebook\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.tokenizer.decode(te1.input_ids,clean_up_tokenization_spaces=True,skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.model.context_max_len= 800\n",
    "generator.model.encoder.context_max_len= 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader,SequentialSampler\n",
    "import tqdm\n",
    "from context_enforcement.data.common import write_to_file\n",
    "import evaluate\n",
    "metrics = evaluate.combine(['bleu','meteor',\"rouge\"])\n",
    "def generate():\n",
    "    test_data_loader = DataLoader(test_dataset,batch_size=12,\n",
    "                                sampler= SequentialSampler(test_dataset),\n",
    "                                collate_fn= SmartCollator(\n",
    "                pad_token_id=train_dataset.tokenizer.pad_token_id,\n",
    "                max_len=configs.max_seq_len,\n",
    "                context_max_len=context_max_len,\n",
    "                context_sampling_bounds=context_sampling_bounds,\n",
    "            \n",
    "            ))\n",
    "\n",
    "    output_summaries =[]\n",
    "    for batch in tqdm.tqdm(test_data_loader):\n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_input_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        seq_len = b_input_ids.shape[1]\n",
    "\n",
    "        context_boundary = compute_context_boundary(seq_len,\n",
    "                                                    context_max_len=110)\n",
    "        \n",
    "        boundary_mask =  batch.get(\"boundary\",)\n",
    "        bb=generator.generate(input_ids=b_input_ids,\n",
    "                attention_mask=b_input_mask,\n",
    "                #context_boundary=boundary_mask,\n",
    "                num_beams=10,\n",
    "                do_sample=False,\n",
    "                num_return_sequences=1,\n",
    "                max_length=140)\n",
    "        sentences = test_dataset.tokenizer.batch_decode(bb,clean_up_tokenization_spaces=True,skip_special_tokens=True)\n",
    "        output_summaries+=sentences\n",
    "    return output_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [tokenizer.decode(c.labels,clean_up_tokenization_spaces=True,skip_special_tokens=True) for c in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating for the context length: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [08:19<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "{'bleu': 0.12346216754890589, 'precisions': [0.4375689199934979, 0.1776036248468456, 0.09612053612814771, 0.05588868746029532], 'brevity_penalty': 0.863722634039824, 'length_ratio': 0.8722170704229669, 'translation_length': 227619, 'reference_length': 260966, 'meteor': 0.35359416748473077, 'rouge1': 0.40248422610308543, 'rouge2': 0.18328221126363148, 'rougeL': 0.33009269996078755, 'rougeLsum': 0.3300614517511684}\n",
      "Generating for the context length: 720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [10:18<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "{'bleu': 0.1257888249451646, 'precisions': [0.4377841740444545, 0.1791020085562382, 0.09760767869694839, 0.05722976542823581], 'brevity_penalty': 0.8695117278704764, 'length_ratio': 0.8773288474360644, 'translation_length': 228953, 'reference_length': 260966, 'meteor': 0.3565514119827842, 'rouge1': 0.4047119203068985, 'rouge2': 0.185856595769887, 'rougeL': 0.332006465804801, 'rougeLsum': 0.33195165056651943}\n",
      "Generating for the context length: 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [10:16<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "{'bleu': 0.1256403068872618, 'precisions': [0.4381767948566864, 0.17878675170700573, 0.09728983506502943, 0.05701369989390655], 'brevity_penalty': 0.8702041264108997, 'length_ratio': 0.8779419541242921, 'translation_length': 229113, 'reference_length': 260966, 'meteor': 0.3563541597980937, 'rouge1': 0.4050806838364527, 'rouge2': 0.18561721029291084, 'rougeL': 0.3319262324656158, 'rougeLsum': 0.33192334002381724}\n",
      "Generating for the context length: 350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [09:11<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "{'bleu': 0.1257626122759007, 'precisions': [0.4382902891885163, 0.17890146449955657, 0.09765710213638545, 0.05715340935321546], 'brevity_penalty': 0.8695030702543955, 'length_ratio': 0.8773211836024616, 'translation_length': 228951, 'reference_length': 260966, 'meteor': 0.3562012415308598, 'rouge1': 0.4047128146167146, 'rouge2': 0.18550529759109602, 'rougeL': 0.33186920040252776, 'rougeLsum': 0.3318646742987025}\n",
      "Generating for the context length: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [07:49<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "{'bleu': 0.11964712510107044, 'precisions': [0.4326436377229051, 0.17240038692776577, 0.0924841374122612, 0.05362138236647655], 'brevity_penalty': 0.8627477081454109, 'length_ratio': 0.8713587210594483, 'translation_length': 227395, 'reference_length': 260966, 'meteor': 0.3474841689817138, 'rouge1': 0.39724258276498764, 'rouge2': 0.17816489836175736, 'rougeL': 0.32460150343422817, 'rougeLsum': 0.32467930362884756}\n"
     ]
    }
   ],
   "source": [
    "context_lens = [200,720,650,350,100]\n",
    "outputs = {}\n",
    "results = {}\n",
    "for cl in context_lens:\n",
    "    print(f'Generating for the context length: {cl}')\n",
    "    generator.model.context_max_len= cl\n",
    "    generator.model.encoder.context_max_len= cl\n",
    "    rbase_output = generate()\n",
    "    outputs[cl] = rbase_output\n",
    "    \n",
    "    write_to_file(rbase_output[:len(test_dataset)], \n",
    "              f\"outputs/multi_context/best_base_final_{cl}\")\n",
    "    \n",
    "    scores = metrics.compute(predictions=rbase_output,references=targets)\n",
    "    print(scores)\n",
    "    \n",
    "    results[cl]= scores\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [08:28<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "base_output = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [10:04<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "generator.model.context_max_len= 800\n",
    "generator.model.encoder.context_max_len= 800\n",
    "base_output8 = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [10:02<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "generator.model.context_max_len= 600\n",
    "generator.model.encoder.context_max_len= 600\n",
    "base_output6 = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [09:30<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "generator.model.context_max_len= 450\n",
    "generator.model.encoder.context_max_len= 450\n",
    "base_output45 = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs(\"outputs/multi_context/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#context_enforcement/data/common.py\n",
    "\n",
    "write_to_file(base_output8[:len(test_dataset)], \n",
    "              \"outputs/multi_context/best_base_final_800\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Musician Koffi Olomide has been taken into custody in the Democratic Republic of Congo, days after he was deported from Kenya for allegedly kicking one of his dancers at an airport in Nairobi.',\n",
       " \"Uganda's Koffi Olomide has been arrested in the Democratic Republic of Congo over an alleged assault on one of his dancers.\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[690],base_output[690]#,base_output_8[690],base_output_45[690]#output_summaries2[690],output_summaries[690],output_summaries6[690],output_summaries8[690]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.12420563480222273,\n",
       " 'precisions': [0.4381499894596304,\n",
       "  0.17908874941070982,\n",
       "  0.09682579940300837,\n",
       "  0.05619688787468894],\n",
       " 'brevity_penalty': 0.864057575751863,\n",
       " 'length_ratio': 0.8725121280166765,\n",
       " 'translation_length': 227696,\n",
       " 'reference_length': 260966,\n",
       " 'meteor': 0.35420455825818364,\n",
       " 'rouge1': 0.4026762188767841,\n",
       " 'rouge2': 0.18481796867562256,\n",
       " 'rougeL': 0.3305624212280963,\n",
       " 'rougeLsum': 0.3305498661301927}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = metrics.compute(predictions=base_output8,references=targets)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.12529167445320155,\n",
       " 'precisions': [0.43767581217045437,\n",
       "  0.1782170041154529,\n",
       "  0.0969340592861464,\n",
       "  0.056633434208437666],\n",
       " 'brevity_penalty': 0.8709825773070866,\n",
       " 'length_ratio': 0.8786316991485481,\n",
       " 'translation_length': 229293,\n",
       " 'reference_length': 260966,\n",
       " 'meteor': 0.35545882674212,\n",
       " 'rouge1': 0.4042558166707959,\n",
       " 'rouge2': 0.18471768845866826,\n",
       " 'rougeL': 0.3318399755379066,\n",
       " 'rougeLsum': 0.33182453398530987}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores45 = metrics.compute(predictions=base_output45,\n",
    "                           references=targets)\n",
    "scores45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.1242693218959997,\n",
       " 'precisions': [0.4397112710255618,\n",
       "  0.17984347696769157,\n",
       "  0.09751670411397062,\n",
       "  0.05682880711450953],\n",
       " 'brevity_penalty': 0.8588878671603885,\n",
       " 'length_ratio': 0.8679674746901895,\n",
       " 'translation_length': 226510,\n",
       " 'reference_length': 260966,\n",
       " 'meteor': 0.3532861459937222,\n",
       " 'rouge1': 0.4033676736623957,\n",
       " 'rouge2': 0.18549005001850066,\n",
       " 'rougeL': 0.3313132654462809,\n",
       " 'rougeLsum': 0.3313118204210047}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'bleu': 0.13001522827171397,\n",
    " 'precisions': [0.43264780948765,\n",
    "  0.17764752271710285,\n",
    "  0.09726789720912225,\n",
    "  0.057229256856921935],\n",
    " 'brevity_penalty': 0.90401138133862,\n",
    " 'length_ratio': 0.9083367181931746,\n",
    " 'translation_length': 237045,\n",
    " 'reference_length': 260966,\n",
    " 'meteor': 0.3623311725177827,\n",
    " 'rouge1': 0.40646161409356885,\n",
    " 'rouge2': 0.18746257090958113,\n",
    " 'rougeL': 0.3322105156464427,\n",
    " 'rougeLsum': 20.3334181119671774}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.12215108883184916,\n",
       " 'precisions': [0.42916968255609556,\n",
       "  0.17216560221044527,\n",
       "  0.0922525258312802,\n",
       "  0.0537097051014124],\n",
       " 'brevity_penalty': 0.8830712157727976,\n",
       " 'length_ratio': 0.8894032172773465,\n",
       " 'translation_length': 232104,\n",
       " 'reference_length': 260966,\n",
       " 'meteor': 0.35137424074129014,\n",
       " 'rouge1': 0.398632967632497,\n",
       " 'rouge2': 0.1799538886903405,\n",
       " 'rougeL': 0.32609557084990337,\n",
       " 'rougeLsum': 0.32622241066447516}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.12300035067772054,\n",
       " 'precisions': [0.4394282548476454,\n",
       "  0.1790089177800281,\n",
       "  0.09666579620313663,\n",
       "  0.056324136455435936],\n",
       " 'brevity_penalty': 0.8550152182505472,\n",
       " 'length_ratio': 0.8645762283209307,\n",
       " 'translation_length': 225625,\n",
       " 'reference_length': 260966,\n",
       " 'meteor': 0.35146299353791816,\n",
       " 'rouge1': 0.4017681486403819,\n",
       " 'rouge2': 0.18375560820687226,\n",
       " 'rougeL': 0.32963068346151203,\n",
       " 'rougeLsum': 0.3296792225053877}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.12202486703008819,\n",
       " 'precisions': [0.43851006174759005,\n",
       "  0.17777018935708405,\n",
       "  0.09596328825046187,\n",
       "  0.05604684262301944],\n",
       " 'brevity_penalty': 0.8527557381282802,\n",
       " 'length_ratio': 0.8626027911681982,\n",
       " 'translation_length': 225110,\n",
       " 'reference_length': 260966,\n",
       " 'meteor': 0.3498951876777049,\n",
       " 'rouge1': 0.40069971264338244,\n",
       " 'rouge2': 0.18265325890345102,\n",
       " 'rougeL': 0.3290151413411355,\n",
       " 'rougeLsum': 0.3290728012119742}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
